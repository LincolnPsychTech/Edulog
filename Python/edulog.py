import requests
import numpy
import pandas
import time
import math
import statistics
import matplotlib.pyplot as mpl

def getval(port, *varargin):
    # Get individual value from specified Eduloggers
    # "port" is the port Eduloggers are connected to, this is visible on the
    # Neulog API window.
    # "loggers" is a one dimensional cell array, with each string specifying
    # the name of a different Edulogger as described in the Neulog API
    # literature:
    # https://neulog.com/wp-content/uploads/2014/06/NeuLog-API-version-7.pdf
    #
    # The output "data" is one row of a structure generated when running an 
    # Edulogger experiment, consisting of one field for each kind of Edulogger 
    # used, containing the measurements taken at each point in data.Time. 
    # Fieldnames should line up with the names specified in "loggers".
    
    if isinstance(varargin[0], (tuple, list)):
        varargin = varargin[0] # Remove extraneous layers
    if not varargin:
        raise Exception("No valid eduloggers selected") # Throw an error if no loggers were supplied
    preface = 'http://localhost:' + str(port) + '/NeuLogAPI?'; # Construct the string to preface any argument passed to the Eduloggers
    val = {};
    for l in varargin: # For each logger...
        resp = requests.get(preface + 'GetSensorValue:[' + l + '],[1]', timeout = 400); # Send request for sensor value
        val[l] = float(''.join([x for x in resp.text if x in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '.', '-']])); # Extract numeric values
    return val



def run(port, dur, *varargin):
    # Run specified Eduloggers for a specified duration at optimal resolution.
    #
    # "port" is the port Eduloggers are connected to, this is visible on the
    # Neulog API window.
    # "dur" is the duration (s) of the clap test, it must be at least 15s for
    # any response to be visible.
    # "loggers" is a one dimensional cell array, with each string specifying
    # the name of a different Edulogger as described in the Neulog API
    # literature:
    # https://neulog.com/wp-content/uploads/2014/06/NeuLog-API-version-7.pdf
    #
    # The output "data" is a structure generated by running an Edulogger experiment,
    # consisting of the following fields:
    # Time: The time (s) since the start of the experiment of each sample.
    # (double)
    # Concern: Whether or not each sample took more than 0.4s  to retrieve (logical)
    # An additional field for each kind of Edulogger used, containing the
    # measurements taken at each point in data.Time. Fieldnames should line up
    # with the names specified in "loggers".
    
    # Get loggers
    eltypes = numpy.load('eltypes.npy'); # Load possible Edulogger types from file
    loggers = [x for x in varargin if any(x == eltypes)]; # Extract variable inputs matching valid types
    
    # Essential checks
    if not loggers: # If no valid loggers provided
        raise Exception("No valid eduloggers selected")
    
    #Run Edulogger
    data = list([]); # Create output structure
    start = time.time(); # Start a timer
    while time.time() < start + dur: # Until the timer reaches sps^-1
        val = getval(port, loggers); # Get value(s) from Edulogger(s)
        val['Time'] = time.time() - start; # Record the time taken
        try:
            val['Concern'] = val['Time'] - data[-1]['Time'] > 0.4; # Did this timer stop at more than 0.4s after the last time?
        except:
            val['Concern'] = val['Time'] > 0.4; # If there is no last time, did it stop at more than 0.4s?
        data.append(val); # Assign measurement to overall data structure
    return pandas.DataFrame(data)



def events(data, *varargin):
    # Apply event data to GSR data, add either a logical array or timestamps as
    # properly formatted events
    #
    # The input "data" is a structure generated by running an Edulogger experiment,
    # consisting of the following fields:
    # Time: The time (s) since the start of the experiment of each sample.
    # (double)
    # Concern: Whether or not each sample took more than twice the specified
    # sample rate to retrieve (logical)
    # An additional field for each kind of Edulogger used, containing the
    # measurements taken at each point in data.Time.
    # 
    # varargin should be string/object pairs, with the name of the event
    # followed by its data, e.g. elevents(data, 'Surprise', [10, 20, 30], 'relax', [5,
    # 15, 25])
    
    args = numpy.reshape(varargin, (math.floor(len(varargin)/2), 2) ); # Reshape input arguments into pairs
    ev = {};
    for a in args:
        ev[a[0]] = a[1] # Reshape argument pairs into dict of event types
    
    for etype in ev: # For each event type...
        data.loc[:,etype] = [False]; # Set initial values to False
        for e in ev[etype]:
            diffs = [abs(n) for n in [ts - e for ts in data.Time]]; # Get difference between current time stamp and all timestamps in data
            i = diffs.index(min(diffs)); # Get index of closest timestamp to event
            data.loc[i, etype] = True; # Set value of event at this timestamp to true
    return data

def gsrsplit(data):
    # Split GSR data into Tonic and Phasic signals.
    #
    # The input "data" is a structure generated by running an Edulogger experiment,
    # consisting of the following fields:
    # Time: The time (s) since the start of the experiment of each sample.
    # (double)
    # Concern: Whether or not each sample took more than twice the specified
    # sample rate to retrieve (logical)
    # GSR: Raw electrodermal data from a GSR edulogger (double)
    # An additional field for each kind of Edulogger used, containing the
    # measurements taken at each point in data.Time.
    # 
    # The output "data" is the same structure which was inputted, with two
    # columns added: Tonic and Phasic, representing the tonic (gradual) and
    # phasic (fast) responses within the supplied GSR data.
    
    diffs = [0]; # Create blank list to store differences
    for n in range(1, len(data)): # For each data point
        diffs.append(data.Time[n] - data.Time[n-1]); # Calculate the difference from the previous value
    sps = int(round(1/statistics.mean(diffs))) # Estimate the number of samples per second
    
    ton = []; # Create blank list to store tonic
    pha = []; # Create blank list to store phasic
    for n in range(len(data)): # For each data point
        if n <= 2*sps: # for the first 2 seconds...
            ton.append( statistics.median(data.GSR[0:n+2*sps]) ); # Take the median of all points up the this one
        elif n >= len(data)-2*sps: # for the last 2 seconds...
            ton.append( statistics.median(data.GSR[n-2*sps:len(data)]) ); # Take the median of all points from this one
        else: # for the rest...
            ton.append( statistics.mean(data.GSR[n-2*sps:n+2*sps]) ); # Take the median of all points 2s either side of the data
        pha.append(data.GSR[n] - ton[n]) # Subtract the tonic value from the original value to get the phasic signal
    data.loc[:, 'Tonic'] = ton; # Append tonic
    data.loc[:, 'Phasic'] = pha; # Append phasic
    
    return data

def scr(data, method):
    # Identify Skin Conductance Responses (SCRs) from GSR data and mark which are event-related and to what event.
    # The input "data" is a structure generated by running an Edulogger experiment,
    # consisting of the following fields:
    # Time: The time (s) since the start of the experiment of each sample.
    # (double)
    # Concern: Whether or not each sample took more than twice the specified
    # sample rate to retrieve (logical)
    # GSR: Raw electrodermal data from a GSR edulogger (double)
    # An additional field for each kind of Edulogger used, containing the
    # measurements taken at each point in data.Time.
    # An additiona field for Tonic and Phasic signals if the GSR data has
    # already been split.
    # 
    # The output "data" is the same structure which was inputted, with two
    # fields added: 
    # SCR: Indicating whether or not a valid SCR took place at the given
    # timestamp (logical)
    # EventRelated: Containing the field names of any events to which a given
    # SCR corresponds (cell)

    try:
        data = data.drop(columns = "SCR") # If there is already an SCR column, delete it
    except:
        pass
    q1 = numpy.percentile(data.Phasic, 25) # Get lower quartile
    q2 = numpy.percentile(data.Phasic, 50) # Get median
    q3 = numpy.percentile(data.Phasic, 75) # Get lower quartile
    sd = statistics.stdev(data.Phasic) # Get standard deviation
    if (method == "median") | (method == "med") | (method == 'median') | (method == 'med'): # If method is "median"...
        data.insert( len(data.columns), "SCR", (data.Phasic < q2 - 2*sd) | (data.Phasic > q2 + 2*sd) ) # Find points where phasic response was +-2sd of q2
    elif (method == "quartiles") | (method == "q") | (method == 'quartiles') | (method == 'q'): # If method is "quartiles"...
        data.insert( len(data.columns), "SCR", (data.Phasic < q1 - 2*sd) | (data.Phasic > q3 + 2*sd) ) # Find points where phasic response was 2sd above / below inter-quartile range
    else:
        data.insert( len(data.columns), "SCR", False)
    
    for peak in data.loc[data.SCR].iterrows(): # For each peak...
        seg = data.loc[ (data.Time > peak[1].Time - 3) & (data.Time < peak[1].Time - 1) ] # Get segment of data at times when a related event could have happened (-1s to -3s of peak)
        for f in seg.columns: # For each column of this segment
            if (data[f].dtype == 'bool') & (f != "SCR"): # If the column is logical and is not the SCR column (so is an event column)
                if sum(seg[f]) > 0: # If an event happened in the segment
                    data.EventRelated[data.Time == peak[1].Time] = data.EventRelated[data.Time == peak[1].Time] + f; # Append the name of the event to the appropriate cell
    return data


def plot(data, *varargin):

    eltypes = numpy.load('eltypes.npy'); # Load possible Edulogger types from file
    loggers = [x for x in varargin if any(x == eltypes)]; # Extract variable inputs matching valid types
    events = [x for x in varargin if any(x != eltypes)]; # Extract variable inputs matching valid types
    
    fig = mpl.figure()
    for l in range(len(loggers)):
        ax = mpl.subplot(len(loggers), 1, l+1)
        ax.set_facecolor([0.98, 0.98, 1])
        ln = mpl.plot(data.Time, data[loggers[l]])
    return fig
        
def liveplot(port, dur, *varargin):
    eltypes = numpy.load('eltypes.npy'); # Load possible Edulogger types from file
    loggers = [x for x in varargin if any(x == eltypes)]; # Extract variable inputs matching valid types
    
    data = list();
    val = getval(port, loggers); # Get value(s) from Edulogger(s)
    val['Time'] = 0; # Record the time taken
    val['Concern'] = False;
    data.append(val); # Assign measurement to overall data structure
    data = pandas.DataFrame(data)
    
    fig = mpl.figure()
    ax = list()
    ln = list()
    for l in range(len(loggers)):
        ax.append( mpl.subplot(len(loggers), 1, l+1) )
        ax[l].set_facecolor([0.98, 0.98, 1])
        ax[l].set_xlim((-25,5))
        ln.append( mpl.plot(data.Time, data[loggers[l]]) )
        
    start = time.time() # Start a timer
    lasttime = 0
    while time.time() - start < dur:
        val = getval(port, loggers) # Get value(s) from Edulogger(s)
        val['Time'] = time.time() - start # Record the time taken
        try:
            val['Concern'] = val['Time'] - data[-1]['Time'] > 0.4 # Did this timer stop at more than 0.4s after the last time?
        except:
            val['Concern'] = val['Time'] > 0.4 # If there is no last time, did it stop at more than 0.4s?
        row = list()
        row.append(val)
        data = data.append(row) # Assign measurement to overall data structure
        for l in range(len(loggers)):
            ln[l][0].set_xdata(data.Time)
            ln[l][0].set_ydata(data[loggers[l]])
            ax[l].set_xlim((n + max(data.Time) - lasttime for n in ax[l].get_xlim()))
        lasttime = time.time() - start
        print(time.time() - start)
    return ax[l].get_xlim()